---
title: 'S3 Data Connector'
sidebar_label: 'S3 Data Connector'
description: 'S3 Data Connector Documentation'
---

Amazon S3 (Simple Storage Service) is a scalable object storage service that allows users to store and retrieve any amount of data at any time from anywhere on the web.

The S3 Data Connector enables federated SQL query on files in [supported formats](/components/data-connectors/index.md#object-store-file-formats) stored in S3 or S3-compatible systems (e.g. MinIO, Cloudflare R2).

```yaml
datasets:
  - from: s3://s3-bucket-name/path/to/parquet/cool_dataset.parquet
    name: cool_dataset
    params:
      s3_auth: key
      s3_key: ${secrets:S3_KEY}
      s3_secret: ${secrets:S3_SECRET}
```

## Configuration

### `from`

The S3-compatible URI to a folder or object in form `from: s3://<bucket>/<file>`

Example: `from: s3://s3-bucket-name/path/to/parquet/cool_dataset.parquet`

If a folder is provided, all child files will be loaded.

### `name`

The dataset name. This will be used as the table name within Spice.

Example:
```yaml
datasets:
  - from: s3://spiceai-demo-datasets/taxi_trips/2024/
    name: cool_dataset
    params:
      ...
```

```sql
SELECT COUNT(*) FROM cool_dataset;
```

```shell
+----------+
| count(*) |
+----------+
| 6001215  |
+----------+
```

### `params`

| Parameter Name   | Description                                                                                                                                                                                                 |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `file_format`    | Specifies the data file format. Required if the format cannot be inferred from the `from` path. See [here](/components/data-connectors/index.md#object-store-file-formats) for supported types and options. |
| `s3_endpoint`    | The S3 endpoint, or equivalent (e.g. MinIO endpoint), for the S3-compatible storage. Defaults to region endpoint. E.g. `s3_endpoint: https://my.minio.server`.                                              |
| `s3_region`      | Region of the S3 bucket, if region specific. Default value is `us-east-1`. E.g. `s3_region: us-east-1`.                                                                                                     |
| `client_timeout` | Specifies timeout for S3 operations. Default value is `30s`. E.g. `client_timeout: 60s`.                                                                                                                    |

More CSV related parameters can be configured, see [CSV Parameters](/reference/file_format.md#csv)

#### Authentication Parameters

Optional for public endpoints. Use the [secret replacement syntax](../secret-stores/index.md) to load the password from a secret store, e.g. `${secrets:my_access_key}`.

| Parameter Name | Description                                                                                                                                                                             |
| -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `s3_auth`      | (Optional) The authentication method to use. Values are `public`, `key` and `iam_role`. Defaults to `public` if `s3_key` and `s3_secret` are not provided, otherwise defaults to `key`. |
| `s3_key`       | The access key (e.g. `AWS_ACCESS_KEY_ID` for AWS).                                                                                                                                      |
| `s3_secret`    | The secret key (e.g. `AWS_SECRET_ACCESS_KEY` for AWS).                                                                                                                                  |

For non-public buckets, `s3_auth: key` or `s3_auth: iam_role` is required. `s3_auth: iam_role` will use the [AWS IAM role](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html) of the currently running instance.

## Examples

### Authenticating using Environment Variables

The environment variables can be defined inline:
```bash
SPICE_S3_KEY=AKIAIOSFODNN7EXAMPLE \
SPICE_S3_SECRET=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
spice run
```

Or in a `.env` file:
```bash
SPICE_S3_KEY=AKIAIOSFODNN7EXAMPLE
SPICE_S3_SECRET=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

Then, in `spicepod.yaml`:
```yaml
version: v1beta1
kind: Spicepod
name: spice-app

secrets:
  - from: env
    name: env

datasets:
  - from: s3://s3-bucket-name/path/to/parquet/cool_dataset.parquet
    name: cool_dataset
    params:
      s3_region: us-east-1
      s3_key: ${env:SPICE_S3_KEY}
      s3_secret: ${env:SPICE_S3_SECRET}
```

Learn more about [Env Secret Store](/components/secret-stores/env).

### Authenticating using Kubernetes secrets

First, create the secret in Kubernetes:

```bash
kubectl create secret generic s3 \
  --from-literal=key='AKIAIOSFODNN7EXAMPLE' \
  --from-literal=secret='wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'
```

Then, in `spicepod.yaml`:
```yaml
version: v1beta1
kind: Spicepod
name: spice-app

secrets:
  - from: kubernetes:s3
    name: s3

datasets:
  - from: s3://s3-bucket-name/path/to/parquet/cool_dataset.parquet
    name: cool_dataset
    params:
      s3_region: us-east-1
      s3_key: ${s3:key}
      s3_secret: ${s3:secret}
```

Learn more about [Kubernetes Secret Store](/components/secret-stores/kubernetes).

### Authenticating using an access key

```yaml
datasets:
  - from: s3://s3-bucket-name/path/to/parquet/cool_dataset.parquet
    name: cool_dataset
    params:
      s3_auth: key
      s3_key: ${secrets:S3_KEY}
      s3_secret: ${secrets:S3_SECRET}
```

### Authenticating using IAM roles

```yaml
datasets:
  - from: s3://s3-bucket-name/path/to/parquet/cool_dataset2.parquet
    name: cool_dataset2
    params:
      s3_auth: iam_role
```

### MinIO Example

Create a dataset named `cool_dataset` from a Parquet file stored in MinIO.

```yaml
- from: s3://s3-bucket-name/path/to/parquet/cool_dataset.parquet
  name: cool_dataset
  params:
    s3_endpoint: https://my.minio.server
    s3_region: 'us-east-1' # Best practice for Minio
```

### S3 Public bucket Example

Create a dataset named `taxi_trips` from a public S3 folder.

```yaml
- from: s3://spiceai-demo-datasets/taxi_trips/2024/
  name: taxi_trips
  params:
    file_format: parquet
```

## Using secrets

There are currently three supported [secret stores](/components/secret-stores/index.md):

* [Environment variables](/components/secret-stores/env)
* [Kubernetes Secret Store](/components/secret-stores/kubernetes)
* [Keyring Secret Store](/components/secret-stores/keyring)

"use strict";(self.webpackChunkspiceaidocs=self.webpackChunkspiceaidocs||[]).push([[6222],{1953:(e,a,c)=>{c.r(a),c.d(a,{assets:()=>i,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var n=c(4848),t=c(8453);const s={title:"Databricks Catalog Connector",sidebar_label:"Databricks",description:"Connect to a Databricks Unity Catalog provider.",sidebar_position:1,pagination_prev:null,pagination_next:null},r=void 0,o={id:"components/catalogs/databricks",title:"Databricks Catalog Connector",description:"Connect to a Databricks Unity Catalog provider.",source:"@site/docs/components/catalogs/databricks.md",sourceDirName:"components/catalogs",slug:"/components/catalogs/databricks",permalink:"/components/catalogs/databricks",draft:!1,unlisted:!1,editUrl:"https://github.com/spiceai/docs/tree/trunk/spiceaidocs/docs/components/catalogs/databricks.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Databricks Catalog Connector",sidebar_label:"Databricks",description:"Connect to a Databricks Unity Catalog provider.",sidebar_position:1,pagination_prev:null,pagination_next:null},sidebar:"docsSidebar"},i={},l=[{value:"Configuration",id:"configuration",level:2},{value:"<code>from</code>",id:"from",level:2},{value:"<code>name</code>",id:"name",level:2},{value:"<code>include</code>",id:"include",level:2},{value:"<code>params</code>",id:"params",level:2},{value:"<code>dataset_params</code>",id:"dataset_params",level:2},{value:"Spark Connect parameters",id:"spark-connect-parameters",level:3},{value:"Delta Lake parameters",id:"delta-lake-parameters",level:3},{value:"AWS S3",id:"aws-s3",level:4},{value:"Azure Blob",id:"azure-blob",level:4},{value:"Google Storage (GCS)",id:"google-storage-gcs",level:4}];function d(e){const a={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(a.p,{children:["Connect to a ",(0,n.jsx)(a.a,{href:"https://www.databricks.com/product/unity-catalog",children:"Databricks Unity Catalog"})," as a catalog provider for federated SQL query using ",(0,n.jsx)(a.a,{href:"https://www.databricks.com/blog/2022/07/07/introducing-spark-connect-the-power-of-apache-spark-everywhere.html",children:"Spark Connect"})," or directly from ",(0,n.jsx)(a.a,{href:"https://delta.io/",children:"Delta Lake"})," tables."]}),"\n",(0,n.jsx)(a.h2,{id:"configuration",children:"Configuration"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-yaml",children:'catalogs:\n  - from: databricks:my_uc_catalog\n    name: uc_catalog # tables from this catalog will be available in the "uc_catalog" catalog in Spice\n    include:\n      - "*.my_table_name" # include only the "my_table_name" tables\n    params:\n      endpoint: dbc-a12cd3e4-56f7.cloud.databricks.com\n      mode: delta_lake # or spark_connect\n    dataset_params:\n      # delta_lake S3 parameters\n      aws_region: us-west-2\n      aws_access_key_id: <aws-access-key-id>\n      aws_secret_access_key: <aws-secret>\n      aws_endpoint: s3.us-west-2.amazonaws.com\n      # spark_connect parameters\n      databricks_cluster_id: 1234-567890-abcde123\n'})}),"\n",(0,n.jsx)(a.h2,{id:"from",children:(0,n.jsx)(a.code,{children:"from"})}),"\n",(0,n.jsxs)(a.p,{children:["The ",(0,n.jsx)(a.code,{children:"from"})," field is used to specify the catalog provider. For Databricks, use ",(0,n.jsx)(a.code,{children:"databricks:<catalog_name>"}),". The ",(0,n.jsx)(a.code,{children:"catalog_name"})," is the name of the catalog in the Databricks Unity Catalog you want to connect to."]}),"\n",(0,n.jsx)(a.h2,{id:"name",children:(0,n.jsx)(a.code,{children:"name"})}),"\n",(0,n.jsxs)(a.p,{children:["The ",(0,n.jsx)(a.code,{children:"name"})," field is used to specify the name of the catalog in Spice. Tables from the Databricks catalog will be available in the schema with this name in Spice. The schema hierarchy of the external catalog is preserved in Spice."]}),"\n",(0,n.jsx)(a.h2,{id:"include",children:(0,n.jsx)(a.code,{children:"include"})}),"\n",(0,n.jsxs)(a.p,{children:["Use the ",(0,n.jsx)(a.code,{children:"include"})," field to specify which tables to include from the catalog. The ",(0,n.jsx)(a.code,{children:"include"})," field supports glob patterns to match multiple tables. For example, ",(0,n.jsx)(a.code,{children:"*.my_table_name"})," would include all tables with the name ",(0,n.jsx)(a.code,{children:"my_table_name"})," in the catalog from any schema. Multiple ",(0,n.jsx)(a.code,{children:"include"})," patterns are OR'ed together and can be specified to include multiple tables."]}),"\n",(0,n.jsx)(a.h2,{id:"params",children:(0,n.jsx)(a.code,{children:"params"})}),"\n",(0,n.jsxs)(a.p,{children:["The ",(0,n.jsx)(a.code,{children:"params"})," field is used to configure the connection to the Databricks Unity Catalog. The following parameters are supported:"]}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"endpoint"}),": The Databricks workspace endpoint, e.g. ",(0,n.jsx)(a.code,{children:"dbc-a12cd3e4-56f7.cloud.databricks.com"}),"."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"token"}),": The Databricks API token to authenticate with the Unity Catalog API. Can also be specified in the ",(0,n.jsx)(a.code,{children:"databricks"})," secret. See the ",(0,n.jsx)(a.a,{href:"/components/data-connectors/databricks",children:"Databricks Data Connector"})," for more information on configuring the secret."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"mode"}),": The execution mode for querying against Databricks. The default is ",(0,n.jsx)(a.code,{children:"spark_connect"}),". Possible values:","\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"spark_connect"}),": Use Spark Connect to query against Databricks. Requires a Spark cluster to be available."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"delta_lake"}),": Query directly from Delta Tables. Requires the object store credentials to be provided, either as a secret or inline in the params."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"databricks_use_ssl"}),": If true, use a TLS connection to connect to the Databricks endpoint. Default is ",(0,n.jsx)(a.code,{children:"true"}),"."]}),"\n"]}),"\n",(0,n.jsx)(a.h2,{id:"dataset_params",children:(0,n.jsx)(a.code,{children:"dataset_params"})}),"\n",(0,n.jsxs)(a.p,{children:["The ",(0,n.jsx)(a.code,{children:"dataset_params"})," field is used to configure the dataset-specific parameters for the catalog. The following parameters are supported:"]}),"\n",(0,n.jsx)(a.h3,{id:"spark-connect-parameters",children:"Spark Connect parameters"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"databricks_cluster_id"}),": The ID of the compute cluster in Databricks to use for the query. e.g. ",(0,n.jsx)(a.code,{children:"1234-567890-abcde123"}),"."]}),"\n"]}),"\n",(0,n.jsx)(a.h3,{id:"delta-lake-parameters",children:"Delta Lake parameters"}),"\n",(0,n.jsxs)(a.p,{children:["These settings can also be configured in the ",(0,n.jsx)(a.code,{children:"databricks"})," secret. See the ",(0,n.jsx)(a.a,{href:"/components/data-connectors/databricks",children:"Databricks Data Connector"})," for more information on configuring the secret."]}),"\n",(0,n.jsx)(a.h4,{id:"aws-s3",children:"AWS S3"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"aws_region"}),": The AWS region for the S3 object store."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"aws_access_key_id"}),": The access key ID for the S3 object store."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"aws_secret_access_key"}),": The secret access key for the S3 object store."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"aws_endpoint"}),": The endpoint for the S3 object store."]}),"\n"]}),"\n",(0,n.jsx)(a.h4,{id:"azure-blob",children:"Azure Blob"}),"\n",(0,n.jsxs)(a.p,{children:["Note: One of the following must be provided: ",(0,n.jsx)(a.code,{children:"azure_storage_account_key"}),", ",(0,n.jsx)(a.code,{children:"azure_storage_client_id"})," and ",(0,n.jsx)(a.code,{children:"azure_storage_client_secret"}),", or ",(0,n.jsx)(a.code,{children:"azure_storage_sas_key"}),"."]}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"azure_storage_account_name"}),": The Azure Storage account name."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"azure_storage_account_key"}),": The Azure Storage master key for accessing the storage account."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"azure_storage_client_id"}),": The service principal client id for accessing the storage account."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"azure_storage_client_secret"}),": The service principal client secret for accessing the storage account."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"azure_storage_sas_key"}),": The shared access signature key for accessing the storage account."]}),"\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"azure_storage_endpoint"}),": The endpoint for the Azure Blob storage account."]}),"\n"]}),"\n",(0,n.jsx)(a.h4,{id:"google-storage-gcs",children:"Google Storage (GCS)"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:[(0,n.jsx)(a.code,{children:"google_service_account"}),": Filesystem path to the Google service account JSON key file."]}),"\n"]})]})}function h(e={}){const{wrapper:a}={...(0,t.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,a,c)=>{c.d(a,{R:()=>r,x:()=>o});var n=c(6540);const t={},s=n.createContext(t);function r(e){const a=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),n.createElement(s.Provider,{value:a},e.children)}}}]);
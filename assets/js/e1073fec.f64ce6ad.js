"use strict";(self.webpackChunkspiceaidocs=self.webpackChunkspiceaidocs||[]).push([[6861],{6131:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var t=a(4848),s=a(8453);const i={title:"AI Gateway - Configuring LLMs",sidebar_label:"AI Gateway",description:"Learn how to configure language models and use Spice as an AI Gateway.",sidebar_position:5,pagination_prev:null,pagination_next:null},r=void 0,o={id:"features/ai-gateway/index",title:"AI Gateway - Configuring LLMs",description:"Learn how to configure language models and use Spice as an AI Gateway.",source:"@site/docs/features/ai-gateway/index.md",sourceDirName:"features/ai-gateway",slug:"/features/ai-gateway/",permalink:"/features/ai-gateway/",draft:!1,unlisted:!1,editUrl:"https://github.com/spiceai/docs/tree/trunk/spiceaidocs/docs/features/ai-gateway/index.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"AI Gateway - Configuring LLMs",sidebar_label:"AI Gateway",description:"Learn how to configure language models and use Spice as an AI Gateway.",sidebar_position:5,pagination_prev:null,pagination_next:null},sidebar:"docsSidebar"},c={},l=[{value:"Configuring Language Models",id:"configuring-language-models",level:2},{value:"Core Features",id:"core-features",level:3}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Spice provides a high-performance, OpenAI API-compatible AI Gateway optimized for managing and scaling large language models (LLMs)."}),"\n",(0,t.jsxs)(n.p,{children:["Additionally, Spice offers tools for Enterprise Retrieval-Augmented Generation (RAG), such as SQL query across federated datasets and an advanced search feature (see ",(0,t.jsx)(n.a,{href:"/features/search",children:"Search"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:["Spice also supports ",(0,t.jsx)(n.strong,{children:"full OpenTelemetry observability"}),", enabling detailed tracking of data flows and requests for full transparency and easier debugging."]}),"\n",(0,t.jsx)(n.h2,{id:"configuring-language-models",children:"Configuring Language Models"}),"\n",(0,t.jsxs)(n.p,{children:["Spice supports a variety of LLMs (see ",(0,t.jsx)(n.a,{href:"/components/models/",children:"Model Components"}),")."]}),"\n",(0,t.jsx)(n.h3,{id:"core-features",children:"Core Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Custom Tools"}),": Equip models with tools to interact with the Spice runtime."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"System Prompts"}),": Customize system prompts and override defaults for ",(0,t.jsx)(n.a,{href:"/api/http/chat-completions",children:(0,t.jsx)(n.code,{children:"v1/chat/completion"})}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["For detailed configuration and API usage, refer to the ",(0,t.jsx)(n.a,{href:"/api",children:"API Documentation"}),"."]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>o});var t=a(6540);const s={},i=t.createContext(s);function r(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);